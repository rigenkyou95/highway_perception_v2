import os
import sys
from typing import Tuple

import cv2
import torch
import numpy as np
import torch.nn as nn

ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
if ROOT not in sys.path:
    sys.path.append(ROOT)


class DepthAnythingV2TinyWrapper(nn.Module):
    """
    Depth Anything V2 Small (vits) å°è£…
    è¾“å…¥ï¼šBGR å›¾åƒ (H, W, 3), np.uint8
    è¾“å‡ºï¼šæ·±åº¦å›¾ (H, W), np.float32
    """

    def __init__(
        self,
        ckpt_path: str,
        device: str = "cuda",
        input_size: int = 518,
    ):
        super().__init__()

        self.device = torch.device(device if torch.cuda.is_available() else "cpu")
        self.input_size = input_size

        from third_party.depth_anything_v2.depth_anything_v2.dpt import DepthAnythingV2

        # ğŸš© å…³é”®ï¼šæŒ‰ Small é…ç½®æ„å»ºæ¨¡å‹ï¼ˆå’Œ vits æƒé‡åŒ¹é…ï¼‰
        self.net = DepthAnythingV2(
            encoder="vits",
            features=64,
            out_channels=[48, 96, 192, 384],
            use_bn=False,
            use_clstoken=False,
        )

        state = torch.load(ckpt_path, map_location=self.device)
        if "model" in state:      # æœ‰çš„ checkpoint å¤–é¢åŒ…äº†ä¸€å±‚
            state = state["model"]

        # ç°åœ¨å½¢çŠ¶åº”è¯¥å®Œå…¨åŒ¹é…ï¼Œå¯ä»¥ strict=True
        self.net.load_state_dict(state, strict=True)
        self.net.to(self.device)
        self.net.eval()

    @torch.no_grad()
    def forward(self, img_bgr: np.ndarray) -> np.ndarray:
        """
        img_bgr: H x W x 3, np.uint8 (OpenCV)
        return: H x W, np.float32
        """
        # ä½¿ç”¨å®˜æ–¹ infer_imageï¼Œé‡Œé¢ä¼šè´Ÿè´£ resize / normalize / to(device)
        depth = self.net.infer_image(img_bgr, input_size=self.input_size)
        depth = depth.astype(np.float32)
        return depth
