import os
import sys
import time
import glob
from typing import Tuple

import cv2
import numpy as np
from tqdm import tqdm

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

# ==== ç”¨äºè‡ªåŠ¨ç”» loss æ›²çº¿ ====
import matplotlib
matplotlib.use("Agg")   # æœåŠ¡å™¨/æ— ç•Œé¢ç¯å¢ƒä¹Ÿå¯ä»¥ç”»å›¾
import matplotlib.pyplot as plt


# ============================================================
# è®¾ç½®é¡¹ç›®æ ¹ç›®å½•ï¼ˆscripts/train/ â†’ ä¸Šä¸¤å±‚ï¼‰
# ============================================================
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
ROOT_DIR = os.path.abspath(os.path.join(CURRENT_DIR, "..", ".."))

if ROOT_DIR not in sys.path:
    sys.path.insert(0, ROOT_DIR)

ROOT = ROOT_DIR

# ============================================================
# æ­£ç¡®å¯¼å…¥ TwinLiteNetPPï¼ˆçº¯æ¨¡å‹ç‰ˆæœ¬ï¼‰
# ============================================================
from models.seg.twinlitenet_pp.TwinLitePP import TwinLiteNetPP


# ============================================================
# è·¯å¾„ & è®­ç»ƒé…ç½®
# ============================================================

class Config:
    # === æ•°æ®è·¯å¾„ï¼ˆä¿æŒä¸ä½ ç¬¬ä¸€æ¬¡è®­ç»ƒä¸€è‡´ï¼‰ ===
    img_train_dir = r"E:\detected sys\lane_detect\data\bdd100k\images\train"
    img_val_dir   = r"E:\detected sys\lane_detect\data\bdd100k\images\val"

    da_train_dir  = r"E:\detected sys\lane_detect\data\bdd100k\segments\train"
    da_val_dir    = r"E:\detected sys\lane_detect\data\bdd100k\segments\val"

    ll_train_dir  = r"E:\detected sys\lane_detect\data\bdd100k\lane\train"
    ll_val_dir    = r"E:\detected sys\lane_detect\data\bdd100k\lane\val"

    # é¢„è®­ç»ƒæƒé‡ï¼ˆTwinLiteNet åŸç‰ˆ best.pthï¼Œå¯é€‰ï¼‰
    pretrained_path = r"E:\detected sys\highway_perception_v2\third_party\TwinLiteNet\pretrained\best.pth"

    # è¾“å‡ºæ¨¡å‹ä¿å­˜ç›®å½•ï¼ˆç»Ÿä¸€åˆ° models/ckpts ä¸‹ï¼‰
    # ç»“æ„ï¼š
    #   models/ckpts/twinlitenetpp_geodepth/
    #       train_log.txt, loss_curves.png,
    #       twinlitenetpp_da_best.pth, twinlitenetpp_lanegeo_best.pth
    #       checkpoints/  (ä¿å­˜å„ä¸ª epoch çš„æƒé‡)
    save_dir = os.path.join(ROOT, "models", "ckpts", "twinlitenetpp_geodepth")
    ckpt_dir = os.path.join(save_dir, "checkpoints")   # å­ç›®å½•ä¸“é—¨æ”¾ epochX æƒé‡

    # è®­ç»ƒå‚æ•°
    num_epochs = 120
    batch_size = 4
    num_workers = 4

    lr = 5e-4
    weight_decay = 1e-4

    img_size = (640, 360)  # å®½,é«˜
    device = "cuda" if torch.cuda.is_available() else "cpu"

    # === æŸå¤±è¶…å‚æ•° ===
    # Tverskyï¼ˆLane åˆ†æ”¯ç”¨ï¼‰
    alpha_tversky = 0.5
    beta_tversky = 0.5

    # ---- Lane è¿ç»­æ€§æƒé‡ï¼ˆå¼±åŒ–ï¼Œé¿å…å‹åˆ¶ DAï¼‰----
    # æœ€ç»ˆ lane_branch_loss = ll_tversky + ll_focal + lambda_lane_cont * ll_cont_raw
    lambda_lane_cont = 0.05

    # Lane åˆ†æ”¯å†…éƒ¨ Tversky / Focal çš„æƒé‡
    lambda_ll_tversky = 1.0
    lambda_ll_focal = 1.0

    # ---- Drivable åˆ†æ”¯ Dice + BCE æ¯”ä¾‹ ----
    # da_branch_loss = 0.6 * Dice + 0.4 * BCE
    lambda_da_dice = 0.6
    lambda_da_bce = 0.4

    # ---- ä¸¤ä¸ªåˆ†æ”¯åœ¨æ€» loss é‡Œçš„æƒé‡ï¼ˆå…³é”®ï¼‰----
    # total_loss = lambda_da_total * da_branch_loss + lambda_ll_total * ll_branch_loss
    lambda_da_total = 1.5   # å¼ºåŒ– DA åˆ†æ”¯
    lambda_ll_total = 1.0   # Lane ä¿æŒ 1.0

    # æ··åˆç²¾åº¦
    use_amp = True


cfg = Config()


# ============================================================
# æ•°æ®é›†å®šä¹‰
# ============================================================

class BDDLaneDrivableDataset(Dataset):
    """
    åŒæ—¶åŠ è½½å›¾åƒ + drivable æ ‡ç­¾ + lane æ ‡ç­¾
    """

    def __init__(self,
                 img_dir: str,
                 da_dir: str,
                 ll_dir: str,
                 img_size: Tuple[int, int] = (640, 360)):
        super().__init__()
        self.img_dir = img_dir
        self.da_dir = da_dir
        self.ll_dir = ll_dir
        self.img_size = img_size

        exts = ["*.jpg", "*.png", "*.jpeg"]
        files = []
        for ext in exts:
            files.extend(glob.glob(os.path.join(img_dir, ext)))
        self.img_paths = sorted(files)

        assert len(self.img_paths) > 0, f"No images found in {img_dir}"

        print(f"[Dataset] {img_dir} -> {len(self.img_paths)} images")

    def __len__(self):
        return len(self.img_paths)

    def __getitem__(self, idx):
        img_path = self.img_paths[idx]
        name = os.path.splitext(os.path.basename(img_path))[0]

        # å›¾åƒ
        img = cv2.imread(img_path)
        if img is None:
            raise FileNotFoundError(img_path)

        img = cv2.resize(img, cfg.img_size)
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0
        img_chw = img_rgb.transpose(2, 0, 1)  # 3xH xW

        # drivable åŒºåŸŸæ ‡ç­¾
        da_path = self._find_label(self.da_dir, name)
        da = cv2.imread(da_path, cv2.IMREAD_GRAYSCALE)
        if da is None:
            raise FileNotFoundError(da_path)
        da = cv2.resize(da, cfg.img_size, interpolation=cv2.INTER_NEAREST)
        # ğŸ”§ å…³é”®ä¿®å¤ï¼šBDD çš„ drivable mask ä¸º 0/1/2ï¼Œä½¿ç”¨ >0 å°† 1/2 éƒ½è§†ä¸ºå‰æ™¯
        da = (da > 0).astype(np.int64)  # 0/1

        # lane æ ‡ç­¾ï¼ˆ0/255ï¼Œä¿æŒ >128ï¼‰
        ll_path = self._find_label(self.ll_dir, name)
        ll = cv2.imread(ll_path, cv2.IMREAD_GRAYSCALE)
        if ll is None:
            raise FileNotFoundError(ll_path)
        ll = cv2.resize(ll, cfg.img_size, interpolation=cv2.INTER_NEAREST)
        ll = (ll > 128).astype(np.int64)  # 0/1

        img_tensor = torch.from_numpy(img_chw).float()
        da_tensor = torch.from_numpy(da).long()
        ll_tensor = torch.from_numpy(ll).long()

        return img_tensor, da_tensor, ll_tensor, name

    def _find_label(self, label_dir: str, name: str) -> str:
        for ext in [".png", ".jpg", ".jpeg"]:
            p = os.path.join(label_dir, name + ext)
            if os.path.exists(p):
                return p
        raise FileNotFoundError(f"Label for {name} not found in {label_dir}")


# ============================================================
# å¯é€‰ï¼šæ•°æ®é›†ä¿®å¤éªŒè¯å‡½æ•°
# ============================================================

def verify_dataset_fix():
    """
    ç®€å•æŠ½å‡ ä¸ªæ ·æœ¬ï¼Œæ£€æŸ¥ï¼š
      - Drivable Area æ˜¯å¦æ˜¯â€œå¡«å……çš„ç™½è‰²åŒºåŸŸâ€ï¼ˆè€Œä¸æ˜¯ç»†çº¿ï¼‰
      - Lane æ˜¯å¦æ˜¯çº¿æ¡
    è¿è¡Œæ–¹å¼ï¼š
      åœ¨å‘½ä»¤è¡Œå•ç‹¬æ‰§è¡Œæœ¬æ–‡ä»¶æ—¶ï¼Œå–æ¶ˆ main() ä¸‹é¢çš„æ³¨é‡Šï¼š
          # verify_dataset_fix(); return
    """
    from torch.utils.data import DataLoader

    dataset = BDDLaneDrivableDataset(
        cfg.img_train_dir, cfg.da_train_dir, cfg.ll_train_dir, img_size=cfg.img_size
    )

    indices = [0, min(100, len(dataset)-1), min(500, len(dataset)-1)]
    n = len(indices)

    fig, axes = plt.subplots(n, 3, figsize=(12, 4 * n))

    if n == 1:
        axes = np.expand_dims(axes, 0)

    for row, idx in enumerate(indices):
        img, da, ll, name = dataset[idx]

        img_vis = img.permute(1, 2, 0).numpy()
        da_vis = da.numpy()
        ll_vis = ll.numpy()

        axes[row, 0].imshow(img_vis)
        axes[row, 0].set_title(f"{name} - åŸå›¾")
        axes[row, 0].axis("off")

        axes[row, 1].imshow(da_vis, cmap="gray", vmin=0, vmax=1)
        axes[row, 1].set_title("Drivable Area (åº”ä¸ºå¡«å……åŒºåŸŸ)")
        axes[row, 1].axis("off")

        axes[row, 2].imshow(ll_vis, cmap="gray", vmin=0, vmax=1)
        axes[row, 2].set_title("Lane Lines")
        axes[row, 2].axis("off")

    plt.tight_layout()
    out_path = os.path.join(cfg.save_dir, "dataset_verification.png")
    os.makedirs(cfg.save_dir, exist_ok=True)
    plt.savefig(out_path, dpi=150)
    plt.close(fig)
    print(f"âœ… æ•°æ®é›†éªŒè¯å›¾å·²ä¿å­˜ï¼š{out_path}")
    print("   è¯·ç›®è§†ç¡®è®¤ï¼šDA ä¸ºå¡«å……é¢ï¼ŒLane ä¸ºçº¿æ¡ã€‚")


# ============================================================
# æŸå¤±å‡½æ•°ï¼šDice / BCE / Tversky / Focal / Lane Continuity
# ============================================================

def tversky_loss(logits, targets, alpha=0.5, beta=0.5, eps=1e-6):
    """
    logits: [N, C, H, W]
    targets: [N, H, W]
    é’ˆå¯¹å‰æ™¯ç±»(1)è®¡ç®— Tversky
    """
    num_classes = logits.shape[1]
    probs = torch.softmax(logits, dim=1)

    targets_1h = F.one_hot(targets, num_classes=num_classes)  # [N,H,W,C]
    targets_1h = targets_1h.permute(0, 3, 1, 2).float()      # [N,C,H,W]

    p1 = probs[:, 1:2]        # [N,1,H,W]
    g1 = targets_1h[:, 1:2]   # [N,1,H,W]

    tp = torch.sum(p1 * g1)
    fp = torch.sum(p1 * (1 - g1))
    fn = torch.sum((1 - p1) * g1)

    tversky = (tp + eps) / (tp + alpha * fp + beta * fn + eps)
    return 1.0 - tversky


def focal_loss(logits, targets, gamma=2.0, alpha=0.25):
    """
    ç®€åŒ–ç‰ˆ Focal Lossï¼Œé’ˆå¯¹å‰æ™¯ç±»
    """
    ce_loss = F.cross_entropy(logits, targets, reduction="none")  # [N,H,W]
    pt = torch.exp(-ce_loss)
    focal = alpha * (1 - pt) ** gamma * ce_loss
    return focal.mean()


def dice_loss_binary_from_logits(logits, targets, eps=1e-6):
    """
    é’ˆå¯¹äºŒç±»åˆ†å‰²çš„ Diceï¼š
    - logits: [N,2,H,W]ï¼ˆTwinLiteNetPP çš„è¾“å‡ºï¼‰
    - targets: [N,H,W]ï¼Œ0/1
    åšæ³•ï¼š
    - å– softmax åå‰æ™¯æ¦‚ç‡ p_fg
    - å’Œ targets(0/1) åš Dice
    """
    probs = torch.softmax(logits, dim=1)[:, 1]  # [N,H,W]
    targets_f = targets.float()

    probs = probs.view(probs.size(0), -1)
    targets_f = targets_f.view(targets_f.size(0), -1)

    intersection = (probs * targets_f).sum(dim=1)
    union = probs.sum(dim=1) + targets_f.sum(dim=1)

    dice = (2 * intersection + eps) / (union + eps)
    loss = 1.0 - dice.mean()
    return loss


def bce_loss_from_two_class_logits(logits, targets):
    """
    logits: [N,2,H,W]
    targets: [N,H,W], 0/1

    æ€è·¯ï¼š
    - å¯¹äºŒåˆ†ç±»æ¥è¯´ï¼š
        logit_fg = logit_1 - logit_0
      åˆ™ sigmoid(logit_fg) = P(class=1 | x)
    - ç„¶åå¯¹ logit_fg ç”¨ BCEWithLogitsï¼Œä¸ 0/1 çš„ targets å¯¹é½ã€‚
    """
    logit_fg = logits[:, 1] - logits[:, 0]     # [N,H,W]
    targets_f = targets.float()
    return F.binary_cross_entropy_with_logits(logit_fg, targets_f)


def lane_continuity_loss_second_order(logits):
    """
    æ›´â€œå‡ ä½•æµâ€å¯¼å‘çš„ lane è¿ç»­æ€§çº¦æŸï¼šäºŒé˜¶å·®åˆ†ï¼ˆåªåœ¨å‚ç›´æ–¹å‘ï¼‰
    å‚è€ƒï¼š
        diff1 = p[:,1:,:] - p[:,:-1,:]
        diff2 = diff1[:,1:,:] - diff1[:,:-1,:]
        loss = mean(|diff2|)
    å³æƒ©ç½šæ¦‚ç‡æ²¿è½¦é“æ–¹å‘çš„â€œå¼¯æŠ˜â€å’Œâ€œå‰§çƒˆå˜åŒ–â€ï¼Œè®©è½¦é“æ›´ç›´ã€æ›´å¹³æ»‘ã€‚
    """
    probs = torch.softmax(logits, dim=1)[:, 1]  # [N,H,W]

    # ä¸€é˜¶å·®åˆ†ï¼ˆå‚ç›´æ–¹å‘ï¼‰
    diff1 = probs[:, 1:, :] - probs[:, :-1, :]       # [N,H-1,W]
    # äºŒé˜¶å·®åˆ†
    diff2 = diff1[:, 1:, :] - diff1[:, :-1, :]       # [N,H-2,W]

    loss = diff2.abs().mean()
    return loss


# ============================================================
# è®­ç»ƒ & éªŒè¯é€»è¾‘
# ============================================================

def train_one_epoch(model, loader, optimizer, scaler, epoch):
    """
    è¿”å›ï¼šè¯¥ epoch çš„å¹³å‡
      - total_loss
      - da_lossï¼ˆdrivable åˆ†æ”¯æ€» lossï¼Œæœªä¹˜ lambda_da_totalï¼‰
      - ll_lossï¼ˆlane åˆ†æ”¯æ€» lossï¼Œæœªä¹˜ lambda_ll_totalï¼‰
    """
    model.train()
    device = cfg.device

    pbar = tqdm(loader, desc=f"Epoch {epoch} [train]", ncols=120)

    sum_loss = 0.0
    sum_da = 0.0
    sum_ll = 0.0
    num = 0

    avg_loss_for_bar = 0.0

    for step, (images, da_targets, ll_targets, names) in enumerate(pbar):
        images = images.to(device, non_blocking=True)
        da_targets = da_targets.to(device, non_blocking=True)
        ll_targets = ll_targets.to(device, non_blocking=True)

        optimizer.zero_grad()

        with torch.cuda.amp.autocast(enabled=cfg.use_amp):
            da_logits, ll_logits = model(images)

            # ===== Drivable åˆ†æ”¯ï¼šDice + BCEï¼ˆåˆ†æ”¯å†…éƒ¨ lossï¼‰ =====
            da_dice = dice_loss_binary_from_logits(da_logits, da_targets)
            da_bce = bce_loss_from_two_class_logits(da_logits, da_targets)
            loss_da_branch = (
                cfg.lambda_da_dice * da_dice +
                cfg.lambda_da_bce * da_bce
            )

            # ===== Lane åˆ†æ”¯ï¼šTversky + Focal + Continuityï¼ˆäºŒé˜¶å·®åˆ†ï¼‰ =====
            ll_tversky = tversky_loss(
                ll_logits, ll_targets,
                alpha=cfg.alpha_tversky,
                beta=cfg.beta_tversky
            )
            ll_focal = focal_loss(ll_logits, ll_targets)
            ll_cont_raw = lane_continuity_loss_second_order(ll_logits)

            loss_ll_branch = (
                cfg.lambda_ll_tversky * ll_tversky +
                cfg.lambda_ll_focal * ll_focal +
                cfg.lambda_lane_cont * ll_cont_raw
            )

            # ===== æ€» lossï¼šDA åˆ†æ”¯æ•´ä½“æƒé‡ 1.5ï¼ŒLane åˆ†æ”¯ 1.0 =====
            loss = (
                cfg.lambda_da_total * loss_da_branch +
                cfg.lambda_ll_total * loss_ll_branch
            )

        if cfg.use_amp and scaler is not None:
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
        else:
            loss.backward()
            optimizer.step()

        sum_loss += loss.item()
        sum_da += loss_da_branch.item()
        sum_ll += loss_ll_branch.item()
        num += 1

        avg_loss_for_bar = (
            avg_loss_for_bar * 0.9 + loss.item() * 0.1
            if step > 0 else loss.item()
        )
        pbar.set_postfix(
            loss=f"{avg_loss_for_bar:.4f}",
            da=f"{loss_da_branch.item():.4f}",
            ll=f"{loss_ll_branch.item():.4f}"
        )

    mean_loss = sum_loss / max(num, 1)
    mean_da = sum_da / max(num, 1)
    mean_ll = sum_ll / max(num, 1)
    return mean_loss, mean_da, mean_ll


def validate(model, loader, epoch):
    """
    éªŒè¯é˜¶æ®µåŒæ ·åˆ†åˆ«ç»Ÿè®¡ï¼š
      - total_val_lossï¼ˆåŒ…å« da_total / ll_total æƒé‡ï¼‰
      - val_da_lossï¼ˆåˆ†æ”¯å†…éƒ¨ lossï¼‰
      - val_ll_lossï¼ˆåˆ†æ”¯å†…éƒ¨ lossï¼‰
    """
    model.eval()
    device = cfg.device

    total_loss = 0.0
    total_da = 0.0
    total_ll = 0.0
    count = 0

    with torch.no_grad():
        pbar = tqdm(loader, desc=f"Epoch {epoch} [val]", ncols=120)
        for step, (images, da_targets, ll_targets, names) in enumerate(pbar):
            images = images.to(device, non_blocking=True)
            da_targets = da_targets.to(device, non_blocking=True)
            ll_targets = ll_targets.to(device, non_blocking=True)

            da_logits, ll_logits = model(images)

            # Drivableï¼šDice + BCEï¼ˆåˆ†æ”¯å†…éƒ¨ lossï¼‰
            da_dice = dice_loss_binary_from_logits(da_logits, da_targets)
            da_bce = bce_loss_from_two_class_logits(da_logits, da_targets)
            loss_da_branch = (
                cfg.lambda_da_dice * da_dice +
                cfg.lambda_da_bce * da_bce
            )

            # Laneï¼šTversky + Focal + Continuityï¼ˆäºŒé˜¶å·®åˆ†ï¼‰
            ll_tversky = tversky_loss(
                ll_logits, ll_targets,
                alpha=cfg.alpha_tversky,
                beta=cfg.beta_tversky
            )
            ll_focal = focal_loss(ll_logits, ll_targets)
            ll_cont_raw = lane_continuity_loss_second_order(ll_logits)

            loss_ll_branch = (
                cfg.lambda_ll_tversky * ll_tversky +
                cfg.lambda_ll_focal * ll_focal +
                cfg.lambda_lane_cont * ll_cont_raw
            )

            loss = (
                cfg.lambda_da_total * loss_da_branch +
                cfg.lambda_ll_total * loss_ll_branch
            )

            total_loss += loss.item()
            total_da += loss_da_branch.item()
            total_ll += loss_ll_branch.item()
            count += 1

            avg_total = total_loss / count
            avg_da = total_da / count
            avg_ll = total_ll / count

            pbar.set_postfix(
                val_loss=f"{avg_total:.4f}",
                val_da=f"{avg_da:.4f}",
                val_ll=f"{avg_ll:.4f}"
            )

    mean_total = total_loss / max(count, 1)
    mean_da = total_da / max(count, 1)
    mean_ll = total_ll / max(count, 1)
    return mean_total, mean_da, mean_ll


# ============================================================
# è®­ç»ƒæ—¥å¿—å¯è§†åŒ–ï¼šè‡ªåŠ¨ç”» loss æ›²çº¿
# ============================================================

def plot_training_curves(log_path: str, out_dir: str):
    """
    è¯»å– train_log.txtï¼Œå¹¶è¾“å‡º loss_curves.pngï¼š
      - subplot(1): total train / val
      - subplot(2): drivable train / val
      - subplot(3): lane train / val
    """
    if not os.path.isfile(log_path):
        print(f"[Plot] Log file not found: {log_path}, è·³è¿‡ç”»å›¾ã€‚")
        return

    try:
        data = np.loadtxt(log_path, delimiter=",")
    except Exception as e:
        print("[Plot] è¯»å–æ—¥å¿—å¤±è´¥:", e)
        return

    if data.ndim == 1:
        data = data[None, :]

    # æ—¥å¿—æ ¼å¼ï¼šepoch, lr,
    #           train_loss, train_da_loss, train_ll_loss,
    #           val_loss, val_da_loss, val_ll_loss
    epoch = data[:, 0]
    train_loss = data[:, 2]
    train_da = data[:, 3]
    train_ll = data[:, 4]
    val_loss = data[:, 5]
    val_da = data[:, 6]
    val_ll = data[:, 7]

    fig, axes = plt.subplots(3, 1, figsize=(8, 10), sharex=True)

    # æ€» loss
    axes[0].plot(epoch, train_loss, label="train_total")
    axes[0].plot(epoch, val_loss, label="val_total")
    axes[0].set_ylabel("Total Loss")
    axes[0].legend()
    axes[0].grid(True, linestyle="--", alpha=0.3)

    # Drivable loss
    axes[1].plot(epoch, train_da, label="train_da")
    axes[1].plot(epoch, val_da, label="val_da")
    axes[1].set_ylabel("DA Loss")
    axes[1].legend()
    axes[1].grid(True, linestyle="--", alpha=0.3)

    # Lane loss
    axes[2].plot(epoch, train_ll, label="train_lane")
    axes[2].plot(epoch, val_ll, label="val_lane")
    axes[2].set_ylabel("Lane Loss")
    axes[2].set_xlabel("Epoch")
    axes[2].legend()
    axes[2].grid(True, linestyle="--", alpha=0.3)

    fig.tight_layout()
    out_path = os.path.join(out_dir, "loss_curves.png")
    fig.savefig(out_path, dpi=200)
    plt.close(fig)

    print("[Plot] Saved training curves to:", out_path)


# ============================================================
# ä¸»å…¥å£
# ============================================================

def main():
    print(f"[INFO] é¡¹ç›®æ ¹ç›®å½• ROOT_DIR: {ROOT_DIR}")
    print("[INFO] sys.path å‰ 5 é¡¹:")
    for p in sys.path[:5]:
        print("   ", p)
    print("============================================================")
    print(f"[INFO] TwinLiteNetPP å¯¼å…¥æˆåŠŸï¼š{TwinLiteNetPP}")

    os.makedirs(cfg.save_dir, exist_ok=True)
    os.makedirs(cfg.ckpt_dir, exist_ok=True)
    print("Save dir :", cfg.save_dir)
    print("Ckpt dir :", cfg.ckpt_dir)
    print("Device :", cfg.device)

    # å¦‚éœ€å…ˆæ£€æŸ¥æ ‡ç­¾æ˜¯å¦æ­£ç¡®ï¼Œå¯å…ˆè¿è¡Œï¼š
    # verify_dataset_fix()
    # return

    # 1. æ„å»ºæ•°æ®é›† & DataLoader
    train_dataset = BDDLaneDrivableDataset(
        cfg.img_train_dir, cfg.da_train_dir, cfg.ll_train_dir, img_size=cfg.img_size
    )
    val_dataset = BDDLaneDrivableDataset(
        cfg.img_val_dir, cfg.da_val_dir, cfg.ll_val_dir, img_size=cfg.img_size
    )

    train_loader = DataLoader(
        train_dataset,
        batch_size=cfg.batch_size,
        shuffle=True,
        num_workers=cfg.num_workers,
        pin_memory=True,
        drop_last=True
    )
    val_loader = DataLoader(
        val_dataset,
        batch_size=cfg.batch_size,
        shuffle=False,
        num_workers=cfg.num_workers,
        pin_memory=True,
        drop_last=False
    )

    # 2. æ„å»ºæ¨¡å‹
    device = cfg.device
    model = TwinLiteNetPP(use_refine=True)

    # åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼ˆå¯é€‰ï¼‰
    if os.path.isfile(cfg.pretrained_path):
        print("Loading pretrained weights from:", cfg.pretrained_path)
        state = torch.load(cfg.pretrained_path, map_location="cpu")
        missing, unexpected = model.load_state_dict(state, strict=False)
        print("missing keys:", missing)
        print("unexpected keys:", unexpected)

    if device == "cuda":
        model = torch.nn.DataParallel(model).to(device)
    else:
        model = model.to(device)

    # 3. ä¼˜åŒ–å™¨ & æ··åˆç²¾åº¦
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=cfg.lr,
        weight_decay=cfg.weight_decay
    )
    scaler = torch.cuda.amp.GradScaler(enabled=cfg.use_amp)

    # åªä¿ç•™ä¸¤ç§â€œbestâ€ï¼šDrivable & Lane å‡ ä½•æµ
    best_da_val = float("inf")     # Drivable ä¸“ç”¨ï¼ˆçœ‹ val_da_lossï¼‰
    best_ll_val = float("inf")     # Lane å‡ ä½•æµä¸“ç”¨ï¼ˆçœ‹ val_ll_lossï¼‰

    log_path = os.path.join(cfg.save_dir, "train_log.txt")

    # 4. è®­ç»ƒå¾ªç¯
    for epoch in range(1, cfg.num_epochs + 1):
        print(f"\n========== Epoch {epoch}/{cfg.num_epochs} ==========")

        train_loss, train_da_loss, train_ll_loss = train_one_epoch(
            model, train_loader, optimizer, scaler, epoch
        )
        val_loss, val_da_loss, val_ll_loss = validate(model, val_loader, epoch)

        current_lr = optimizer.param_groups[0]["lr"]

        print(
            f"[Epoch {epoch}/{cfg.num_epochs}] "
            f"LR={current_lr:.6e} | "
            f"train_loss={train_loss:.4f} "
            f"(da={train_da_loss:.4f}, ll={train_ll_loss:.4f}) | "
            f"val_loss={val_loss:.4f} "
            f"(da={val_da_loss:.4f}, ll={val_ll_loss:.4f})"
        )

        # è®°å½•æ—¥å¿—ï¼ˆä¾›ç”»å›¾ä½¿ç”¨ï¼‰
        with open(log_path, "a", encoding="utf-8") as f:
            f.write(
                f"{epoch},{current_lr:.6e},"
                f"{train_loss:.6f},{train_da_loss:.6f},{train_ll_loss:.6f},"
                f"{val_loss:.6f},{val_da_loss:.6f},{val_ll_loss:.6f}\n"
            )

        # Drivable ä¸“ç”¨ bestï¼ˆçœ‹ val_da_lossï¼‰
        if val_da_loss < best_da_val:
            best_da_val = val_da_loss
            save_path = os.path.join(cfg.save_dir, "twinlitenetpp_da_best.pth")
            torch.save(model.state_dict(), save_path)
            print(f"[BEST-DA] val_da_loss improved to {best_da_val:.4f}. Saved to {save_path}")

        # Lane å‡ ä½•æµä¸“ç”¨ bestï¼ˆçœ‹ val_ll_lossï¼‰
        if val_ll_loss < best_ll_val:
            best_ll_val = val_ll_loss
            save_path = os.path.join(cfg.save_dir, "twinlitenetpp_lanegeo_best.pth")
            torch.save(model.state_dict(), save_path)
            print(f"[BEST-LANE] val_ll_loss improved to {best_ll_val:.4f}. Saved to {save_path}")

        # æ¯éš”è‹¥å¹² epoch ä¿å­˜ä¸€ä¸ªæ™®é€š ckptï¼ˆæ–¹ä¾¿ä¹‹åå¯¹æ¯”ï¼‰
        if epoch % 10 == 0:
            ckpt_path = os.path.join(cfg.ckpt_dir, f"twinlitenetpp_epoch{epoch}.pth")
            torch.save(model.state_dict(), ckpt_path)
            print(f"[CKPT] Saved checkpoint to {ckpt_path}")

    # 5. è®­ç»ƒç»“æŸåç”» loss æ›²çº¿
    plot_training_curves(log_path, cfg.save_dir)


if __name__ == "__main__":
    main()
